{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "URsvvKM9Q2Wl"
      },
      "outputs": [],
      "source": [
        "# Par exemple, au début de train_model.py :\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# On peut forcer la base des données ici\n",
        "# BASE_DIR = Path(\"/content/drive/MyDrive/PROJET_IA/...\")\n",
        "# mais normalement le parser argparse s’en charge.\n",
        "\n",
        "# Vérifie que l’usage est bien :\n",
        "# python scripts/train_model.py --data data/export_IA.csv --models-dir models scripts/train_model.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAaTxdMvUslo",
        "outputId": "980f9a7f-aaa6-48e7-984b-4ded2ab45aa4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-12 23:28:14.776403: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-12 23:28:16.868178: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\Paul\\Documents\\GitHub\\Projet_Outil_de_l-ing-_S6\\IA\\besoin4\\train_model.py\", line 144, in <module>\n",
            "    main()\n",
            "  File \"c:\\Users\\Paul\\Documents\\GitHub\\Projet_Outil_de_l-ing-_S6\\IA\\besoin4\\train_model.py\", line 126, in main\n",
            "    tf.config.experimental.set_memory_growth(\n",
            "  File \"c:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\config.py\", line 754, in set_memory_growth\n",
            "    context.context().set_memory_growth(device, enable)\n",
            "  File \"c:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 1982, in set_memory_growth\n",
            "    raise ValueError(\"Unrecognized device: %s\" % repr(dev))\n",
            "ValueError: Unrecognized device: None\n"
          ]
        }
      ],
      "source": [
        "!python train_model.py --csv After_Sort.csv --models-dir models --max-samples 50000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_ZoKSzAXXZa",
        "outputId": "070746d0-8611-4618-c4fb-82deaa3d5051"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Données chargées: 258102 lignes, 112 navires\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-12 23:28:45.468068: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-12 23:28:47.259246: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\Paul\\Documents\\GitHub\\Projet_Outil_de_l-ing-_S6\\IA\\besoin4\\predict_position.py\", line 210, in <module>\n",
            "    main()\n",
            "  File \"c:\\Users\\Paul\\Documents\\GitHub\\Projet_Outil_de_l-ing-_S6\\IA\\besoin4\\predict_position.py\", line 165, in main\n",
            "    X_sequences, mmsis, timestamps = create_sequences_for_prediction(data, SEQUENCE_LENGTH)\n",
            "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Paul\\Documents\\GitHub\\Projet_Outil_de_l-ing-_S6\\IA\\besoin4\\predict_position.py\", line 50, in create_sequences_for_prediction\n",
            "    seq_data = group[FEATURE_COLS].iloc[i:i+seq_len].values\n",
            "               ~~~~~^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\", line 4122, in __getitem__\n",
            "    data = self._take_with_is_copy(indexer, axis=1)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\", line 4172, in _take_with_is_copy\n",
            "    result = self.take(indices=indices, axis=axis)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\", line 4152, in take\n",
            "    new_data = self._mgr.take(\n",
            "               ^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 894, in take\n",
            "    return self.reindex_indexer(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 680, in reindex_indexer\n",
            "    new_blocks = self._slice_take_blocks_ax0(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 843, in _slice_take_blocks_ax0\n",
            "    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 1373, in take_nd\n",
            "    new_values = algos.take_nd(\n",
            "                 ^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py\", line 117, in take_nd\n",
            "    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py\", line 157, in _take_nd_ndarray\n",
            "    out = np.empty(out_shape, dtype=dtype)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 177. KiB for an array with shape (5, 4523) and data type float64\n"
          ]
        }
      ],
      "source": [
        "!python predict_position.py --input After_Sort.csv --models-dir models --output preds.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "Wc6w6LcwVRzi",
        "outputId": "c1eb2c42-0cdb-4f9b-8109-7db3461e2b98"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the predictions from the CSV file\n",
        "preds = pd.read_csv('preds.csv')\n",
        "\n",
        "# Load the true data from the CSV file, specifying dtypes to handle mixed types\n",
        "true_df = pd.read_csv('data/export_IA.csv', dtype={'VesselName': str, 'IMO': str, 'CallSign': str, 'VesselType': str, 'Status': str})\n",
        "\n",
        "\n",
        "# 1. Créer une colonne \"Date_Pred\" dans preds = BaseDateTime + Horizon_min minutes\n",
        "preds['BaseDateTime'] = pd.to_datetime(preds['BaseDateTime']) # Convert BaseDateTime to datetime\n",
        "preds['Date_Pred'] = preds['BaseDateTime'] + pd.to_timedelta(preds['Horizon_min'], unit='m')\n",
        "\n",
        "# Convert BaseDateTime in true_df to datetime\n",
        "true_df['BaseDateTime'] = pd.to_datetime(true_df['BaseDateTime'])\n",
        "\n",
        "# Renommer les colonnes LAT et LON pour les vraies données in true_df\n",
        "true_df = true_df.rename(columns={\"LAT\": \"True_LAT\", \"LON\": \"True_LON\"})\n",
        "\n",
        "\n",
        "# 2. Trier les dataframes par MMSI et date (nécessaire pour merge_asof dans chaque groupe)\n",
        "preds = preds.sort_values(['MMSI', 'Date_Pred']).reset_index(drop=True)\n",
        "true_df = true_df.sort_values(['MMSI', 'BaseDateTime']).reset_index(drop=True)\n",
        "\n",
        "# Group by MMSI and perform merge_asof for each group\n",
        "merged_list = []\n",
        "for mmsi, preds_group in preds.groupby(\"MMSI\"):\n",
        "    true_group = true_df[true_df[\"MMSI\"] == mmsi].copy()\n",
        "\n",
        "    if not true_group.empty:\n",
        "        merged_group = pd.merge_asof(\n",
        "            preds_group,\n",
        "            true_group[['BaseDateTime', 'True_LAT', 'True_LON']],\n",
        "            left_on='Date_Pred',\n",
        "            right_on='BaseDateTime',\n",
        "            direction='nearest',  # nearest c’est mieux que 'backward' pour plus de précision\n",
        "            tolerance=pd.Timedelta('5min')  # tolérance max, à ajuster si besoin\n",
        "        )\n",
        "        merged_list.append(merged_group)\n",
        "\n",
        "# Concatenate the results\n",
        "merged = pd.concat(merged_list, ignore_index=True)\n",
        "\n",
        "\n",
        "# Display the head of the merged DataFrame to check the result\n",
        "print(\"Head of the merged DataFrame:\")\n",
        "display(merged.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        },
        "id": "YrpJx-zMAhDL",
        "outputId": "61f2e510-93c5-4db7-f5e7-fcdb94a6d87a"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "from datetime import timedelta\n",
        "from math import radians, sin, cos, sqrt, atan2\n",
        "\n",
        "# Fonction haversine pour calculer la distance entre deux points GPS\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    R = 6371  # rayon de la Terre en km\n",
        "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "\n",
        "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
        "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
        "    return R * c  # distance en km\n",
        "\n",
        "# Forcer le type datetime et trier\n",
        "preds[\"BaseDateTime\"] = pd.to_datetime(preds[\"BaseDateTime\"])\n",
        "true_df[\"BaseDateTime\"] = pd.to_datetime(true_df[\"BaseDateTime\"])\n",
        "preds = preds.sort_values(\"BaseDateTime\")\n",
        "true_df = true_df.sort_values(\"BaseDateTime\")\n",
        "\n",
        "# Filtrer uniquement les prédictions à 5 min\n",
        "preds_5min = preds[preds[\"Horizon_min\"] == 5]\n",
        "\n",
        "# Limiter à 10 bateaux\n",
        "mmsi_list = preds_5min[\"MMSI\"].unique()[:50]\n",
        "\n",
        "# Calcul du centre de la carte\n",
        "initial_points = []\n",
        "for mmsi in mmsi_list:\n",
        "    true_mmsi = true_df[true_df[\"MMSI\"] == mmsi]\n",
        "    preds_mmsi = preds_5min[preds_5min[\"MMSI\"] == mmsi]\n",
        "    if true_mmsi.empty or preds_mmsi.empty:\n",
        "        continue\n",
        "    initial_time = preds_mmsi.iloc[0][\"BaseDateTime\"]\n",
        "    init_real_point = true_mmsi[true_mmsi[\"BaseDateTime\"] == initial_time]\n",
        "    if not init_real_point.empty:\n",
        "        initial_points.append((\n",
        "            init_real_point[\"True_LAT\"].iloc[0],\n",
        "            init_real_point[\"True_LON\"].iloc[0]\n",
        "        ))\n",
        "\n",
        "if initial_points:\n",
        "    avg_lat = sum([p[0] for p in initial_points]) / len(initial_points)\n",
        "    avg_lon = sum([p[1] for p in initial_points]) / len(initial_points)\n",
        "else:\n",
        "    first_pred = preds_5min.iloc[0]\n",
        "    avg_lat, avg_lon = first_pred[\"Predicted_LAT\"], first_pred[\"Predicted_LON\"]\n",
        "\n",
        "# Créer la carte centrée\n",
        "m = folium.Map(location=[avg_lat, avg_lon], zoom_start=8)\n",
        "\n",
        "# Boucle sur chaque bateau limité à 10\n",
        "for mmsi in mmsi_list:\n",
        "    preds_mmsi = preds_5min[preds_5min[\"MMSI\"] == mmsi].copy()\n",
        "    true_mmsi = true_df[true_df[\"MMSI\"] == mmsi].copy()\n",
        "\n",
        "    if preds_mmsi.empty or true_mmsi.empty:\n",
        "        continue\n",
        "\n",
        "    row = preds_mmsi.iloc[0]\n",
        "    initial_time = row[\"BaseDateTime\"]\n",
        "    pred_time = initial_time + timedelta(minutes=int(row[\"Horizon_min\"]))\n",
        "\n",
        "    pred_lat = row[\"Predicted_LAT\"]\n",
        "    pred_lon = row[\"Predicted_LON\"]\n",
        "\n",
        "    window = timedelta(minutes=2)\n",
        "    nearby = true_mmsi[\n",
        "        (true_mmsi[\"BaseDateTime\"] >= pred_time - window) &\n",
        "        (true_mmsi[\"BaseDateTime\"] <= pred_time + window)\n",
        "    ]\n",
        "\n",
        "    if not nearby.empty:\n",
        "        real_lat = nearby[\"True_LAT\"].mean()\n",
        "        real_lon = nearby[\"True_LON\"].mean()\n",
        "    else:\n",
        "        real_lat = None\n",
        "        real_lon = None\n",
        "\n",
        "    initial_real_point = true_mmsi[true_mmsi[\"BaseDateTime\"] == initial_time]\n",
        "\n",
        "    # Marqueur point initial réel\n",
        "    if not initial_real_point.empty:\n",
        "        folium.Marker(\n",
        "            location=[initial_real_point[\"True_LAT\"].iloc[0], initial_real_point[\"True_LON\"].iloc[0]],\n",
        "            popup=f\"Bateau {mmsi} - Initial Real\",\n",
        "            icon=folium.Icon(color=\"green\", icon=\"ship\", prefix='fa')\n",
        "        ).add_to(m)\n",
        "\n",
        "    # Marqueur prédiction\n",
        "    folium.Marker(\n",
        "        location=[pred_lat, pred_lon],\n",
        "        popup=f\"Bateau {mmsi} - Prediction +5min\",\n",
        "        icon=folium.Icon(color=\"blue\", icon=\"hourglass-half\", prefix='fa')\n",
        "    ).add_to(m)\n",
        "\n",
        "    # Marqueur position réelle correspondante\n",
        "    if real_lat is not None and real_lon is not None:\n",
        "        folium.Marker(\n",
        "            location=[real_lat, real_lon],\n",
        "            popup=f\"Bateau {mmsi} - True +5min (approximated)\",\n",
        "            icon=folium.Icon(color=\"red\", icon=\"map-marker\", prefix='fa')\n",
        "        ).add_to(m)\n",
        "\n",
        "        # Calcul distance et ajout d'une ligne entre les 2 points\n",
        "        dist_km = haversine(pred_lat, pred_lon, real_lat, real_lon)\n",
        "\n",
        "        # Ligne entre la position prédite et réelle\n",
        "        folium.PolyLine(\n",
        "            locations=[(pred_lat, pred_lon), (real_lat, real_lon)],\n",
        "            color=\"purple\",\n",
        "            weight=2,\n",
        "            opacity=0.7,\n",
        "            popup=f\"Distance: {dist_km:.2f} km\"\n",
        "        ).add_to(m)\n",
        "\n",
        "        # Popup distance sur la ligne (il faut contourner car PolyLine n'a pas de popup natif)\n",
        "        midpoint = [(pred_lat + real_lat) / 2, (pred_lon + real_lon) / 2]\n",
        "        folium.Marker(\n",
        "            location=midpoint,\n",
        "            icon=folium.DivIcon(\n",
        "                html=f'<div style=\"font-size:12px; color:purple; font-weight:bold;\">{dist_km:.2f} km</div>'\n",
        "            )\n",
        "        ).add_to(m)\n",
        "\n",
        "# Sauvegarder et afficher la carte\n",
        "m.save(\"map_10_bateaux_distance.html\")\n",
        "print(\"Carte sauvegardée : map_10_bateaux_distance.html\")\n",
        "\n",
        "display(m)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
