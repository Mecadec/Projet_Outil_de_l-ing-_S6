{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61bbd2aa",
   "metadata": {},
   "source": [
    "Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94dff4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4873d106",
   "metadata": {},
   "source": [
    "création de la dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "420875e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"After_Sort.csv\", parse_dates=[\"BaseDateTime\"])\n",
    "df.sort_values(\"BaseDateTime\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b1045d",
   "metadata": {},
   "source": [
    "print informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab3ce7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id       MMSI BaseDateTime       LAT       LON   SOG    COG  \\\n",
      "117352  9030257  563020500   2023-05-25  28.82655 -89.43528  14.2  207.9   \n",
      "117395  9032593  366954420   2023-05-25  27.77639 -82.63030   0.1  294.9   \n",
      "117339  9029199  215583000   2023-05-25  26.48967 -79.39617  10.2  182.7   \n",
      "117360  9030460  367181550   2023-05-25  29.85450 -89.98148   0.0  298.2   \n",
      "117442  9036191  368045410   2023-05-25  27.84124 -97.06945   5.9   15.5   \n",
      "\n",
      "        Heading        VesselName            IMO CallSign  VesselType  Status  \\\n",
      "117352    206.0       MERCURY SKY     IMO9796949   9V5148          70       0   \n",
      "117395    294.0  PROVINCETOWN III     IMO9329394  WDB8185          60       0   \n",
      "117339    184.0         COBIA LNG     IMO9869306  9HA5192          84       0   \n",
      "117360      NaN   BELLE CHASSE II            NaN  WDD7069          60       0   \n",
      "117442      NaN    JOSEPH F WEBER  IMO1012865430  WDK3453          60       0   \n",
      "\n",
      "        Length  Width  Draft  Cargo TransceiverClass  \n",
      "117352     NaN    NaN    NaN   70.0                A  \n",
      "117395    30.0    9.0    1.9   60.0                A  \n",
      "117339   299.0   46.0    9.4   84.0                A  \n",
      "117360    41.0   16.0    NaN   60.0                A  \n",
      "117442    46.0   16.0    3.3   60.0                A  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 411723 entries, 117352 to 402776\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   id                411723 non-null  int64         \n",
      " 1   MMSI              411723 non-null  int64         \n",
      " 2   BaseDateTime      411723 non-null  datetime64[ns]\n",
      " 3   LAT               411723 non-null  float64       \n",
      " 4   LON               411723 non-null  float64       \n",
      " 5   SOG               411723 non-null  float64       \n",
      " 6   COG               371787 non-null  float64       \n",
      " 7   Heading           267527 non-null  float64       \n",
      " 8   VesselName        411723 non-null  object        \n",
      " 9   IMO               297387 non-null  object        \n",
      " 10  CallSign          409921 non-null  object        \n",
      " 11  VesselType        411723 non-null  int64         \n",
      " 12  Status            411723 non-null  int64         \n",
      " 13  Length            393426 non-null  float64       \n",
      " 14  Width             367428 non-null  float64       \n",
      " 15  Draft             268706 non-null  float64       \n",
      " 16  Cargo             409615 non-null  float64       \n",
      " 17  TransceiverClass  411723 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(9), int64(4), object(4)\n",
      "memory usage: 59.7+ MB\n",
      "None\n",
      "                 id          MMSI                   BaseDateTime  \\\n",
      "count  4.117230e+05  4.117230e+05                         411723   \n",
      "mean   1.676658e+07  4.051087e+08  2023-05-28 11:51:24.290372096   \n",
      "min    8.200000e+01  2.057760e+08            2023-05-25 00:00:00   \n",
      "25%    7.845310e+06  3.670212e+08            2023-05-27 00:25:34   \n",
      "50%    1.645390e+07  3.675990e+08            2023-05-29 01:04:08   \n",
      "75%    2.570430e+07  4.771376e+08     2023-05-29 22:15:20.500000   \n",
      "max    3.518632e+07  6.718300e+08            2023-05-31 23:59:59   \n",
      "std    1.031064e+07  1.081609e+08                            NaN   \n",
      "\n",
      "                 LAT            LON            SOG            COG  \\\n",
      "count  411723.000000  411723.000000  411723.000000  371787.000000   \n",
      "mean       28.665941     -90.065868       3.354600     194.007270   \n",
      "min        23.386430     -97.396580       0.000000       0.000000   \n",
      "25%        27.878770     -94.448555       0.000000     115.000000   \n",
      "50%        29.258580     -90.209540       0.000000     207.100000   \n",
      "75%        29.725690     -89.098555       5.800000     277.000000   \n",
      "max        31.998470     -76.492140      34.400000     359.900000   \n",
      "std         1.454098       5.166867       5.836501     101.812955   \n",
      "\n",
      "             Heading     VesselType         Status         Length  \\\n",
      "count  267527.000000  411723.000000  411723.000000  393426.000000   \n",
      "mean      183.661765      68.682051       3.004178     117.467420   \n",
      "min         0.000000      60.000000       0.000000       0.000000   \n",
      "25%        85.000000      60.000000       0.000000      35.000000   \n",
      "50%       177.000000      70.000000       0.000000      87.000000   \n",
      "75%       288.000000      80.000000       5.000000     185.000000   \n",
      "max       359.000000      89.000000      15.000000     334.000000   \n",
      "std       112.251487       8.574370       5.011241      93.638247   \n",
      "\n",
      "               Width          Draft          Cargo  \n",
      "count  367428.000000  268706.000000  409615.000000  \n",
      "mean       21.005672       7.607627      66.746289  \n",
      "min         0.000000       0.000000       0.000000  \n",
      "25%         9.000000       3.300000      60.000000  \n",
      "50%        18.000000       8.200000      70.000000  \n",
      "75%        32.000000      11.000000      80.000000  \n",
      "max        60.000000      20.400000      99.000000  \n",
      "std        14.050956       4.440219      18.136256  \n",
      "VesselType\n",
      "60    174436\n",
      "70    106852\n",
      "80     97889\n",
      "71      6879\n",
      "89      6805\n",
      "79      5543\n",
      "69      5517\n",
      "82      2511\n",
      "74      1959\n",
      "61      1840\n",
      "84      1492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df[\"VesselType\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6be89a",
   "metadata": {},
   "source": [
    "ajout des colones lat et long +5, +10, +15 et delta_temps à la dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8768f914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id       MMSI BaseDateTime       LAT       LON   SOG    COG  \\\n",
      "117352  9030257  563020500   2023-05-25  28.82655 -89.43528  14.2  207.9   \n",
      "117395  9032593  366954420   2023-05-25  27.77639 -82.63030   0.1  294.9   \n",
      "117339  9029199  215583000   2023-05-25  26.48967 -79.39617  10.2  182.7   \n",
      "117360  9030460  367181550   2023-05-25  29.85450 -89.98148   0.0  298.2   \n",
      "117442  9036191  368045410   2023-05-25  27.84124 -97.06945   5.9   15.5   \n",
      "\n",
      "        Heading        VesselName            IMO  ... Draft  Cargo  \\\n",
      "117352    206.0       MERCURY SKY     IMO9796949  ...   NaN   70.0   \n",
      "117395    294.0  PROVINCETOWN III     IMO9329394  ...   1.9   60.0   \n",
      "117339    184.0         COBIA LNG     IMO9869306  ...   9.4   84.0   \n",
      "117360      NaN   BELLE CHASSE II            NaN  ...   NaN   60.0   \n",
      "117442      NaN    JOSEPH F WEBER  IMO1012865430  ...   3.3   60.0   \n",
      "\n",
      "        TransceiverClass  LONG_5  LAT_5  LONG_10  LAT_10 LONG_15 LAT_15  \\\n",
      "117352                 A    None   None     None    None    None   None   \n",
      "117395                 A    None   None     None    None    None   None   \n",
      "117339                 A    None   None     None    None    None   None   \n",
      "117360                 A    None   None     None    None    None   None   \n",
      "117442                 A    None   None     None    None    None   None   \n",
      "\n",
      "       Delta_temps  \n",
      "117352        None  \n",
      "117395        None  \n",
      "117339        None  \n",
      "117360        None  \n",
      "117442        None  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "nouvelles_colonnes = ['LONG_5', 'LAT_5', 'LONG_10', 'LAT_10', 'LONG_15', 'LAT_15','Delta_temps']\n",
    "\n",
    "# Ajout des colonnes avec des valeurs vides (NaN)\n",
    "for col in nouvelles_colonnes:\n",
    "    df[col] = None  # ou pd.NA, ou np.nan si vous utilisez numpy\n",
    "\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e701a7f",
   "metadata": {},
   "source": [
    "Remplissage de la colonne Delta_temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9464cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Delta_temps'] = df.sort_values(['MMSI', 'BaseDateTime']).groupby('MMSI')['BaseDateTime'].diff().dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b6f8e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu du résultat :\n",
      "             MMSI        BaseDateTime       LAT       LON  LAT_5     LAT_5  \\\n",
      "117823  205776000 2023-05-25 00:07:27  25.95847 -97.37876   None  28.42186   \n",
      "118169  205776000 2023-05-25 00:13:27  25.95846 -97.37880   None  29.27150   \n",
      "118391  205776000 2023-05-25 00:16:27  25.95847 -97.37880   None  28.49450   \n",
      "125113  205776000 2023-05-25 00:31:27  25.95848 -97.37879   None  29.63941   \n",
      "120283  205776000 2023-05-25 00:34:27  25.95846 -97.37882   None  29.34030   \n",
      "119768  205776000 2023-05-25 00:37:27  25.95848 -97.37882   None  29.95513   \n",
      "120279  205776000 2023-05-25 00:40:27  25.95846 -97.37883   None  29.10751   \n",
      "121098  205776000 2023-05-25 00:43:27  25.95849 -97.37879   None  29.05616   \n",
      "121336  205776000 2023-05-25 00:46:27  25.95846 -97.37878   None  28.34240   \n",
      "120988  205776000 2023-05-25 00:55:27  25.95842 -97.37880   None  29.77716   \n",
      "\n",
      "           LAT_5  LONG_5    LONG_5    LONG_5  ...    LAT_10 LONG_10   LONG_10  \\\n",
      "117823  29.25482    None -93.22272 -89.96854  ...  29.25484    None -93.20471   \n",
      "118169  29.79502    None -94.56672 -93.32482  ...  29.79502    None -94.57908   \n",
      "118391  29.60287    None -93.32632 -89.86643  ...  29.60288    None -93.31553   \n",
      "125113  26.17363    None -89.94084 -95.80343  ...  26.17596    None -89.95501   \n",
      "120283  29.65459    None -92.69079 -93.82770  ...  29.67344    None -92.69081   \n",
      "119768  30.44086    None -90.06213 -91.19245  ...  30.44084    None -90.06213   \n",
      "120279  29.57692    None -88.88142 -93.27764  ...  29.59350    None -88.88389   \n",
      "121098  27.84376    None -88.96452 -97.07034  ...  27.84376    None -88.96453   \n",
      "121336  26.11514    None -93.09418 -80.07527  ...  26.11514    None -93.07681   \n",
      "120988       NaN    None -92.17641       NaN  ...  29.29342    None -92.17642   \n",
      "\n",
      "         LONG_10 LAT_15    LAT_15    LAT_15 LONG_15   LONG_15   LONG_15  \n",
      "117823 -89.96855   None  28.40132  29.25485    None -93.18942 -89.96853  \n",
      "118169 -93.32482   None  29.29098  29.79503    None -94.59119 -93.32483  \n",
      "118391 -89.86641   None  28.47513  29.60290    None -93.29685 -89.86644  \n",
      "125113 -95.78374   None  29.66390  26.17858    None -89.95788 -95.76345  \n",
      "120283 -93.83291   None  29.34033  29.68841    None -92.69080 -93.83743  \n",
      "119768 -91.19244   None  29.95515  30.44085    None -90.06213 -91.19244  \n",
      "120279 -93.29243   None  29.13099  29.60667    None -88.88576 -93.30424  \n",
      "121098 -97.07035   None  29.05615  27.84375    None -88.96453 -97.07036  \n",
      "121336 -80.07519   None  28.32184  26.11513    None -93.06079 -80.07526  \n",
      "120988 -94.55334   None  29.77716  29.29342    None -92.17639 -94.55340  \n",
      "\n",
      "[10 rows x 22 columns]\n",
      "\n",
      "Informations sur le remplissage des colonnes cibles :\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 411723 entries, 117823 to 402623\n",
      "Data columns (total 18 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   LAT_5    0 non-null       object \n",
      " 1   LAT_5    402952 non-null  float64\n",
      " 2   LAT_5    402952 non-null  float64\n",
      " 3   LONG_5   0 non-null       object \n",
      " 4   LONG_5   402952 non-null  float64\n",
      " 5   LONG_5   402952 non-null  float64\n",
      " 6   LAT_10   0 non-null       object \n",
      " 7   LAT_10   406544 non-null  float64\n",
      " 8   LAT_10   406544 non-null  float64\n",
      " 9   LONG_10  0 non-null       object \n",
      " 10  LONG_10  406544 non-null  float64\n",
      " 11  LONG_10  406544 non-null  float64\n",
      " 12  LAT_15   0 non-null       object \n",
      " 13  LAT_15   405853 non-null  float64\n",
      " 14  LAT_15   405853 non-null  float64\n",
      " 15  LONG_15  0 non-null       object \n",
      " 16  LONG_15  405853 non-null  float64\n",
      " 17  LONG_15  405853 non-null  float64\n",
      "dtypes: float64(12), object(6)\n",
      "memory usage: 59.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Assurez-vous que le DataFrame est trié par MMSI et par temps, c'est crucial pour la suite.\n",
    "df.sort_values(['MMSI', 'BaseDateTime'], inplace=True)\n",
    "\n",
    "# Créez une copie du dataframe qui servira de table de recherche pour les positions futures.\n",
    "df_lookup = df[['MMSI', 'BaseDateTime', 'LAT', 'LON']].copy()\n",
    "\n",
    "# --- Fonction corrigée pour trouver les cibles pour un horizon donné ---\n",
    "def find_future_positions(main_df, lookup_df, horizon_min, tolerance_sec):\n",
    "    \"\"\"\n",
    "    Trouve la position future pour chaque ligne du dataframe principal en utilisant une méthode robuste.\n",
    "    \"\"\"\n",
    "    # Créez une copie pour éviter de modifier les dataframes originaux\n",
    "    df_temp = main_df.copy()\n",
    "    \n",
    "    # Calculez le temps cible pour la recherche\n",
    "    df_temp['target_time'] = df_temp['BaseDateTime'] + pd.Timedelta(minutes=horizon_min)\n",
    "    \n",
    "    # Fusionnez pour trouver la position la plus proche dans le futur.\n",
    "    # On utilise 'suffixes' pour gérer les colonnes LAT/LON qui existent dans les deux dataframes.\n",
    "    # Les colonnes de 'lookup_df' (right) auront le suffixe '_future'.\n",
    "    merged_df = pd.merge_asof(\n",
    "        left=df_temp.sort_values('target_time'),\n",
    "        right=lookup_df.sort_values('BaseDateTime'),\n",
    "        left_on='target_time',\n",
    "        right_on='BaseDateTime',\n",
    "        by='MMSI',\n",
    "        direction='nearest',\n",
    "        tolerance=pd.Timedelta(seconds=tolerance_sec),\n",
    "        suffixes=('', '_future') \n",
    "    )\n",
    "    \n",
    "    # Renommer les colonnes nouvellement ajoutées au format souhaité (ex: LAT_5, LONG_5)\n",
    "    # C'est ici la correction majeure : on renomme APRES la fusion.\n",
    "    rename_dict = {\n",
    "        'LAT_future': f'LAT_{horizon_min}',\n",
    "        'LON_future': f'LONG_{horizon_min}'\n",
    "    }\n",
    "    merged_df.rename(columns=rename_dict, inplace=True)\n",
    "    \n",
    "    # Rétablissez l'ordre initial du dataframe\n",
    "    merged_df.sort_index(inplace=True)\n",
    "    \n",
    "    # Retournez juste les colonnes cibles\n",
    "    return merged_df[[f'LAT_{horizon_min}', f'LONG_{horizon_min}']]\n",
    "\n",
    "# --- Appliquez la fonction pour chaque horizon ---\n",
    "targets_5 = find_future_positions(df, df_lookup, 5, 120)\n",
    "targets_10 = find_future_positions(df, df_lookup, 10, 300)\n",
    "targets_15 = find_future_positions(df, df_lookup, 15, 420)\n",
    "\n",
    "# --- Concaténez les nouvelles colonnes au dataframe original ---\n",
    "# On supprime d'abord les anciennes colonnes cibles si elles existent\n",
    "df.drop(columns=['LONG_5', 'LAT_5', 'LONG_10', 'LAT_10', 'LONG_15', 'LAT_15'], inplace=True, errors='ignore')\n",
    "\n",
    "# On concatène les nouvelles cibles.\n",
    "df = pd.concat([df, targets_5, targets_10, targets_15], axis=1)\n",
    "\n",
    "# --- Vérification ---\n",
    "print(\"Aperçu du résultat :\")\n",
    "print(df[['MMSI', 'BaseDateTime', 'LAT', 'LON', 'LAT_5', 'LONG_5', 'LAT_10', 'LONG_10', 'LAT_15', 'LONG_15']].head(10))\n",
    "\n",
    "print(\"\\nInformations sur le remplissage des colonnes cibles :\")\n",
    "print(df[['LAT_5', 'LONG_5', 'LAT_10', 'LONG_10', 'LAT_15', 'LONG_15']].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa85602",
   "metadata": {},
   "source": [
    "Séparation en bases d'apprentissage, test et validation par MMSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d61b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de MMSI uniques:\n",
      "Train: 97\n",
      "Test : 30\n",
      "Val  : 22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Récupération des MMSI uniques et suppr valeurs manquantes\n",
    "mmsi_uniques = df['MMSI'].dropna().unique()\n",
    "\n",
    "# Mélange aléatoire\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(mmsi_uniques)\n",
    "\n",
    "# Affectation fixe : 97 pour apprentissage, 30 pour test, 22 pour validation\n",
    "n_train = 97\n",
    "n_test = 30\n",
    "n_val = 22\n",
    "\n",
    "mmsi_train = mmsi_uniques[:n_train]\n",
    "mmsi_test = mmsi_uniques[n_train:n_train + n_test]\n",
    "mmsi_val = mmsi_uniques[n_train + n_test:n_train + n_test + n_val]\n",
    "\n",
    "# Création des trois sous-ensembles\n",
    "df_train = df[df['MMSI'].isin(mmsi_train)]\n",
    "df_test = df[df['MMSI'].isin(mmsi_test)]\n",
    "df_val = df[df['MMSI'].isin(mmsi_val)]\n",
    "\n",
    "# Affichage pour vérification\n",
    "print(\"Nombre de MMSI uniques:\")\n",
    "print(\"Train:\", df_train['MMSI'].nunique())\n",
    "print(\"Test :\", df_test['MMSI'].nunique())\n",
    "print(\"Val  :\", df_val['MMSI'].nunique())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55fde09",
   "metadata": {},
   "source": [
    "Observation de début de chaque df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771eaa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.head(5))\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"  ===============================================================  \")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(df_test.head(5))\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"  ===============================================================  \")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(df_val.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24268a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sort_values([\"MMSI\",\"BaseDateTime\"], inplace=True)\n",
    "print(df_train.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c849721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Taille de l'ensemble d'apprentissage : {len(df_train)}\")\n",
    "print(f\"Taille de l'ensemble de test : {len(df_test)}\")\n",
    "print(f\"Taille de l'ensemble de validation : {len(df_val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f5eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sort_values([\"MMSI\",\"BaseDateTime\"], inplace=True)\n",
    "print(df_train.head())\n",
    "# print(df_train.iloc[2950:3000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a171d1",
   "metadata": {},
   "source": [
    "prendre entre 295 et 305sec\n",
    "prendre entre 595 et 605sec\n",
    "prendre entre 895 et 905sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44602cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpoler_positions_dataframe(df):\n",
    "    \"\"\"\n",
    "    Fonction pour interpoler les positions à 5, 10 et 15 minutes\n",
    "    pour un dataframe donné\n",
    "    \"\"\"\n",
    "    # Créer une copie pour éviter les warnings\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Trier par MMSI et datetime pour assurer l'ordre chronologique\n",
    "    df_copy = df_copy.sort_values(['MMSI', 'BaseDateTime']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Début de l'interpolation pour {len(df_copy)} lignes...\")\n",
    "    \n",
    "    # Parcourir chaque navire\n",
    "    for mmsi in df_copy['MMSI'].unique():\n",
    "        # Filtrer les données du navire actuel\n",
    "        mask_navire = df_copy['MMSI'] == mmsi\n",
    "        indices_navire = df_copy[mask_navire].index.tolist()\n",
    "        \n",
    "        # Parcourir les positions de ce navire\n",
    "        for i in range(len(indices_navire) - 1):\n",
    "            idx_actuel = indices_navire[i]\n",
    "            idx_suivant = indices_navire[i + 1]\n",
    "            \n",
    "            # Récupérer les positions et temps\n",
    "            lat_A = df_copy.loc[idx_actuel, 'LAT']\n",
    "            lon_A = df_copy.loc[idx_actuel, 'LON']\n",
    "            time_A = df_copy.loc[idx_actuel, 'BaseDateTime']\n",
    "            \n",
    "            lat_B = df_copy.loc[idx_suivant, 'LAT']\n",
    "            lon_B = df_copy.loc[idx_suivant, 'LON']\n",
    "            time_B = df_copy.loc[idx_suivant, 'BaseDateTime']\n",
    "            \n",
    "            # Calculer l'intervalle de temps en secondes\n",
    "            delta_temps = (time_B - time_A).total_seconds()\n",
    "            \n",
    "            # Interpolation à 5 minutes (300s)\n",
    "            if delta_temps >= 300:\n",
    "                fraction_5min = 300 / delta_temps\n",
    "                lat_5min = lat_A + fraction_5min * (lat_B - lat_A)\n",
    "                lon_5min = lon_A + fraction_5min * (lon_B - lon_A)\n",
    "                \n",
    "                df_copy.loc[idx_actuel, 'LAT_5'] = lat_5min\n",
    "                df_copy.loc[idx_actuel, 'LONG_5'] = lon_5min\n",
    "            \n",
    "            # Interpolation à 10 minutes (600s)\n",
    "            if delta_temps >= 600:\n",
    "                fraction_10min = 600 / delta_temps\n",
    "                lat_10min = lat_A + fraction_10min * (lat_B - lat_A)\n",
    "                lon_10min = lon_A + fraction_10min * (lon_B - lon_A)\n",
    "                \n",
    "                df_copy.loc[idx_actuel, 'LAT_10'] = lat_10min\n",
    "                df_copy.loc[idx_actuel, 'LONG_10'] = lon_10min\n",
    "            \n",
    "            # Interpolation à 15 minutes (900s)\n",
    "            if delta_temps >= 900:\n",
    "                fraction_15min = 900 / delta_temps\n",
    "                lat_15min = lat_A + fraction_15min * (lat_B - lat_A)\n",
    "                lon_15min = lon_A + fraction_15min * (lon_B - lon_A)\n",
    "                \n",
    "                df_copy.loc[idx_actuel, 'LAT_15'] = lat_15min\n",
    "                df_copy.loc[idx_actuel, 'LONG_15'] = lon_15min\n",
    "    \n",
    "    print(\"Interpolation terminée !\")\n",
    "    return df_copy\n",
    "\n",
    "# Application de l'interpolation sur les trois ensembles\n",
    "print(\"=== INTERPOLATION DE L'ENSEMBLE D'APPRENTISSAGE ===\")\n",
    "df_train_interpolated = interpoler_positions_dataframe(df_train)\n",
    "\n",
    "print(\"\\n=== INTERPOLATION DE L'ENSEMBLE DE TEST ===\")\n",
    "df_test_interpolated = interpoler_positions_dataframe(df_test)\n",
    "\n",
    "print(\"\\n=== INTERPOLATION DE L'ENSEMBLE DE VALIDATION ===\")\n",
    "df_val_interpolated = interpoler_positions_dataframe(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad118743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier_interpolation(df, nom_ensemble):\n",
    "    \"\"\"\n",
    "    Fonction pour vérifier les résultats de l'interpolation\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== VÉRIFICATION - {nom_ensemble} ===\")\n",
    "    \n",
    "    # Compter les valeurs non nulles pour chaque colonne d'interpolation\n",
    "    interpolations_5min = df['LAT_5'].notna().sum()\n",
    "    interpolations_10min = df['LAT_10'].notna().sum()\n",
    "    interpolations_15min = df['LAT_15'].notna().sum()\n",
    "    \n",
    "    print(f\"Interpolations à 5 minutes : {interpolations_5min}\")\n",
    "    print(f\"Interpolations à 10 minutes : {interpolations_10min}\")\n",
    "    print(f\"Interpolations à 15 minutes : {interpolations_15min}\")\n",
    "    \n",
    "    # Afficher quelques exemples d'interpolation\n",
    "    exemples = df[df['LAT_5'].notna()].head(3)\n",
    "    if len(exemples) > 0:\n",
    "        print(f\"\\nExemples d'interpolation à 5 minutes :\")\n",
    "        for idx, row in exemples.iterrows():\n",
    "            print(f\"MMSI {row['MMSI']} : Position originale ({row['LAT']:.5f}, {row['LON']:.5f}) -> Position à +5min ({row['LAT_5']:.5f}, {row['LONG_5']:.5f})\")\n",
    "\n",
    "# Vérification des trois ensembles\n",
    "verifier_interpolation(df_train_interpolated, \"TRAIN\")\n",
    "verifier_interpolation(df_test_interpolated, \"TEST\")\n",
    "verifier_interpolation(df_val_interpolated, \"VALIDATION\")\n",
    "\n",
    "print(\"\\n=== INTERPOLATION TERMINÉE POUR TOUS LES ENSEMBLES ===\")\n",
    "print(\"Les DataFrames df_train_interpolated, df_test_interpolated et df_val_interpolated\")\n",
    "print(\"contiennent maintenant les positions interpolées dans les colonnes LAT_5, LONG_5, LAT_10, LONG_10, LAT_15, LONG_15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12511e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seuil_SOG = 0.5  # à ajuster selon ton dataset\n",
    "df_filtre = df[df['SOG'] > seuil_SOG].reset_index(drop=True)\n",
    "len(df_filtre)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
