{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61bbd2aa",
   "metadata": {},
   "source": [
    "Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94dff4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4873d106",
   "metadata": {},
   "source": [
    "création de la dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "420875e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"After_Sort.csv\", parse_dates=[\"BaseDateTime\"])\n",
    "df.sort_values(\"BaseDateTime\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b1045d",
   "metadata": {},
   "source": [
    "print informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab3ce7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id       MMSI BaseDateTime       LAT       LON   SOG    COG  \\\n",
      "117352  9030257  563020500   2023-05-25  28.82655 -89.43528  14.2  207.9   \n",
      "117395  9032593  366954420   2023-05-25  27.77639 -82.63030   0.1  294.9   \n",
      "117339  9029199  215583000   2023-05-25  26.48967 -79.39617  10.2  182.7   \n",
      "117360  9030460  367181550   2023-05-25  29.85450 -89.98148   0.0  298.2   \n",
      "117442  9036191  368045410   2023-05-25  27.84124 -97.06945   5.9   15.5   \n",
      "\n",
      "        Heading        VesselName            IMO CallSign  VesselType  Status  \\\n",
      "117352    206.0       MERCURY SKY     IMO9796949   9V5148          70       0   \n",
      "117395    294.0  PROVINCETOWN III     IMO9329394  WDB8185          60       0   \n",
      "117339    184.0         COBIA LNG     IMO9869306  9HA5192          84       0   \n",
      "117360      NaN   BELLE CHASSE II            NaN  WDD7069          60       0   \n",
      "117442      NaN    JOSEPH F WEBER  IMO1012865430  WDK3453          60       0   \n",
      "\n",
      "        Length  Width  Draft  Cargo TransceiverClass  \n",
      "117352     NaN    NaN    NaN   70.0                A  \n",
      "117395    30.0    9.0    1.9   60.0                A  \n",
      "117339   299.0   46.0    9.4   84.0                A  \n",
      "117360    41.0   16.0    NaN   60.0                A  \n",
      "117442    46.0   16.0    3.3   60.0                A  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 411723 entries, 117352 to 402776\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   id                411723 non-null  int64         \n",
      " 1   MMSI              411723 non-null  int64         \n",
      " 2   BaseDateTime      411723 non-null  datetime64[ns]\n",
      " 3   LAT               411723 non-null  float64       \n",
      " 4   LON               411723 non-null  float64       \n",
      " 5   SOG               411723 non-null  float64       \n",
      " 6   COG               371787 non-null  float64       \n",
      " 7   Heading           267527 non-null  float64       \n",
      " 8   VesselName        411723 non-null  object        \n",
      " 9   IMO               297387 non-null  object        \n",
      " 10  CallSign          409921 non-null  object        \n",
      " 11  VesselType        411723 non-null  int64         \n",
      " 12  Status            411723 non-null  int64         \n",
      " 13  Length            393426 non-null  float64       \n",
      " 14  Width             367428 non-null  float64       \n",
      " 15  Draft             268706 non-null  float64       \n",
      " 16  Cargo             409615 non-null  float64       \n",
      " 17  TransceiverClass  411723 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(9), int64(4), object(4)\n",
      "memory usage: 59.7+ MB\n",
      "None\n",
      "                 id          MMSI                   BaseDateTime  \\\n",
      "count  4.117230e+05  4.117230e+05                         411723   \n",
      "mean   1.676658e+07  4.051087e+08  2023-05-28 11:51:24.290372096   \n",
      "min    8.200000e+01  2.057760e+08            2023-05-25 00:00:00   \n",
      "25%    7.845310e+06  3.670212e+08            2023-05-27 00:25:34   \n",
      "50%    1.645390e+07  3.675990e+08            2023-05-29 01:04:08   \n",
      "75%    2.570430e+07  4.771376e+08     2023-05-29 22:15:20.500000   \n",
      "max    3.518632e+07  6.718300e+08            2023-05-31 23:59:59   \n",
      "std    1.031064e+07  1.081609e+08                            NaN   \n",
      "\n",
      "                 LAT            LON            SOG            COG  \\\n",
      "count  411723.000000  411723.000000  411723.000000  371787.000000   \n",
      "mean       28.665941     -90.065868       3.354600     194.007270   \n",
      "min        23.386430     -97.396580       0.000000       0.000000   \n",
      "25%        27.878770     -94.448555       0.000000     115.000000   \n",
      "50%        29.258580     -90.209540       0.000000     207.100000   \n",
      "75%        29.725690     -89.098555       5.800000     277.000000   \n",
      "max        31.998470     -76.492140      34.400000     359.900000   \n",
      "std         1.454098       5.166867       5.836501     101.812955   \n",
      "\n",
      "             Heading     VesselType         Status         Length  \\\n",
      "count  267527.000000  411723.000000  411723.000000  393426.000000   \n",
      "mean      183.661765      68.682051       3.004178     117.467420   \n",
      "min         0.000000      60.000000       0.000000       0.000000   \n",
      "25%        85.000000      60.000000       0.000000      35.000000   \n",
      "50%       177.000000      70.000000       0.000000      87.000000   \n",
      "75%       288.000000      80.000000       5.000000     185.000000   \n",
      "max       359.000000      89.000000      15.000000     334.000000   \n",
      "std       112.251487       8.574370       5.011241      93.638247   \n",
      "\n",
      "               Width          Draft          Cargo  \n",
      "count  367428.000000  268706.000000  409615.000000  \n",
      "mean       21.005672       7.607627      66.746289  \n",
      "min         0.000000       0.000000       0.000000  \n",
      "25%         9.000000       3.300000      60.000000  \n",
      "50%        18.000000       8.200000      70.000000  \n",
      "75%        32.000000      11.000000      80.000000  \n",
      "max        60.000000      20.400000      99.000000  \n",
      "std        14.050956       4.440219      18.136256  \n",
      "VesselType\n",
      "60    174436\n",
      "70    106852\n",
      "80     97889\n",
      "71      6879\n",
      "89      6805\n",
      "79      5543\n",
      "69      5517\n",
      "82      2511\n",
      "74      1959\n",
      "61      1840\n",
      "84      1492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df[\"VesselType\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6be89a",
   "metadata": {},
   "source": [
    "ajout des colones lat et long +5, +10, +15 et delta_temps à la dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8768f914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id       MMSI BaseDateTime       LAT       LON   SOG    COG  \\\n",
      "117352  9030257  563020500   2023-05-25  28.82655 -89.43528  14.2  207.9   \n",
      "117395  9032593  366954420   2023-05-25  27.77639 -82.63030   0.1  294.9   \n",
      "117339  9029199  215583000   2023-05-25  26.48967 -79.39617  10.2  182.7   \n",
      "117360  9030460  367181550   2023-05-25  29.85450 -89.98148   0.0  298.2   \n",
      "117442  9036191  368045410   2023-05-25  27.84124 -97.06945   5.9   15.5   \n",
      "\n",
      "        Heading        VesselName            IMO  ... Draft  Cargo  \\\n",
      "117352    206.0       MERCURY SKY     IMO9796949  ...   NaN   70.0   \n",
      "117395    294.0  PROVINCETOWN III     IMO9329394  ...   1.9   60.0   \n",
      "117339    184.0         COBIA LNG     IMO9869306  ...   9.4   84.0   \n",
      "117360      NaN   BELLE CHASSE II            NaN  ...   NaN   60.0   \n",
      "117442      NaN    JOSEPH F WEBER  IMO1012865430  ...   3.3   60.0   \n",
      "\n",
      "        TransceiverClass  LONG_5  LAT_5  LONG_10  LAT_10 LONG_15 LAT_15  \\\n",
      "117352                 A    None   None     None    None    None   None   \n",
      "117395                 A    None   None     None    None    None   None   \n",
      "117339                 A    None   None     None    None    None   None   \n",
      "117360                 A    None   None     None    None    None   None   \n",
      "117442                 A    None   None     None    None    None   None   \n",
      "\n",
      "       Delta_temps  \n",
      "117352        None  \n",
      "117395        None  \n",
      "117339        None  \n",
      "117360        None  \n",
      "117442        None  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "nouvelles_colonnes = ['LONG_5', 'LAT_5', 'LONG_10', 'LAT_10', 'LONG_15', 'LAT_15','Delta_temps']\n",
    "\n",
    "# Ajout des colonnes avec des valeurs vides (NaN)\n",
    "for col in nouvelles_colonnes:\n",
    "    df[col] = None  # ou pd.NA, ou np.nan si vous utilisez numpy\n",
    "\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e701a7f",
   "metadata": {},
   "source": [
    "Remplissage de la colonne Delta_temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9464cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Delta_temps'] = df.sort_values(['MMSI', 'BaseDateTime']).groupby('MMSI')['BaseDateTime'].diff().dt.total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4ffa5a",
   "metadata": {},
   "source": [
    "OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b6f8e8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set a DataFrame with multiple columns to the single column temp_LAT_5",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_22768\\1810036999.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     36\u001b[39m \n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# --- CORRECTION FINALE : Méthode en 3 étapes pour éviter les erreurs de doublons ---\u001b[39;00m\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# 1. Assignez les résultats à des colonnes temporaires\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m df[\u001b[33m'temp_LAT_5'\u001b[39m] = targets_5[\u001b[33m'LAT_5'\u001b[39m]\n\u001b[32m     41\u001b[39m df[\u001b[33m'temp_LONG_5'\u001b[39m] = targets_5[\u001b[33m'LONG_5'\u001b[39m]\n\u001b[32m     42\u001b[39m df[\u001b[33m'temp_LAT_10'\u001b[39m] = targets_10[\u001b[33m'LAT_10'\u001b[39m]\n\u001b[32m     43\u001b[39m df[\u001b[33m'temp_LONG_10'\u001b[39m] = targets_10[\u001b[33m'LONG_10'\u001b[39m]\n",
      "\u001b[32mc:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4302\u001b[39m             self._setitem_frame(key, value)\n\u001b[32m   4303\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m isinstance(key, (Series, np.ndarray, list, Index)):\n\u001b[32m   4304\u001b[39m             self._setitem_array(key, value)\n\u001b[32m   4305\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m isinstance(value, DataFrame):\n\u001b[32m-> \u001b[39m\u001b[32m4306\u001b[39m             self._set_item_frame_value(key, value)\n\u001b[32m   4307\u001b[39m         elif (\n\u001b[32m   4308\u001b[39m             is_list_like(value)\n\u001b[32m   4309\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m self.columns.is_unique\n",
      "\u001b[32mc:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4460\u001b[39m \n\u001b[32m   4461\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.isetitem(locs, value)\n\u001b[32m   4462\u001b[39m \n\u001b[32m   4463\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m len(value.columns) > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m4464\u001b[39m             raise ValueError(\n\u001b[32m   4465\u001b[39m                 \u001b[33m\"Cannot set a DataFrame with multiple columns to the single \"\u001b[39m\n\u001b[32m   4466\u001b[39m                 \u001b[33mf\"column {key}\"\u001b[39m\n\u001b[32m   4467\u001b[39m             )\n",
      "\u001b[31mValueError\u001b[39m: Cannot set a DataFrame with multiple columns to the single column temp_LAT_5"
     ]
    }
   ],
   "source": [
    "# Assurez-vous que le DataFrame est trié par MMSI et par temps\n",
    "df.sort_values(['MMSI', 'BaseDateTime'], inplace=True)\n",
    "\n",
    "# Créez une copie du dataframe qui servira de table de recherche\n",
    "df_lookup = df[['MMSI', 'BaseDateTime', 'LAT', 'LON']].copy()\n",
    "\n",
    "# --- Fonction (inchangée et correcte) ---\n",
    "def find_future_positions(main_df, lookup_df, horizon_min, tolerance_sec):\n",
    "    df_temp = main_df.copy()\n",
    "    df_temp['target_time'] = df_temp['BaseDateTime'] + pd.Timedelta(minutes=horizon_min)\n",
    "    \n",
    "    merged_df = pd.merge_asof(\n",
    "        left=df_temp.sort_values('target_time'),\n",
    "        right=lookup_df.sort_values('BaseDateTime'),\n",
    "        left_on='target_time',\n",
    "        right_on='BaseDateTime',\n",
    "        by='MMSI',\n",
    "        direction='nearest',\n",
    "        tolerance=pd.Timedelta(seconds=tolerance_sec),\n",
    "        suffixes=('', '_future')\n",
    "    )\n",
    "    \n",
    "    rename_dict = {\n",
    "        'LAT_future': f'LAT_{horizon_min}',\n",
    "        'LON_future': f'LONG_{horizon_min}'\n",
    "    }\n",
    "    merged_df.rename(columns=rename_dict, inplace=True)\n",
    "    merged_df.sort_index(inplace=True)\n",
    "    \n",
    "    return merged_df[[f'LAT_{horizon_min}', f'LONG_{horizon_min}']]\n",
    "\n",
    "# --- Appliquez la fonction pour chaque horizon ---\n",
    "targets_5 = find_future_positions(df, df_lookup, 5, 120)\n",
    "targets_10 = find_future_positions(df, df_lookup, 10, 300)\n",
    "targets_15 = find_future_positions(df, df_lookup, 15, 420)\n",
    "\n",
    "# --- CORRECTION FINALE : Méthode en 3 étapes pour éviter les erreurs de doublons ---\n",
    "\n",
    "# 1. Assignez les résultats à des colonnes temporaires\n",
    "df['temp_LAT_5'] = targets_5['LAT_5']\n",
    "df['temp_LONG_5'] = targets_5['LONG_5']\n",
    "df['temp_LAT_10'] = targets_10['LAT_10']\n",
    "df['temp_LONG_10'] = targets_10['LONG_10']\n",
    "df['temp_LAT_15'] = targets_15['LAT_15']\n",
    "df['temp_LONG_15'] = targets_15['LONG_15']\n",
    "\n",
    "# 2. Supprimez TOUTES les anciennes versions des colonnes cibles (y compris les doublons)\n",
    "cols_to_drop = ['LAT_5', 'LONG_5', 'LAT_10', 'LONG_10', 'LAT_15', 'LONG_15']\n",
    "df.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# 3. Renommez les colonnes temporaires avec leurs noms finaux\n",
    "rename_dict = {\n",
    "    'temp_LAT_5': 'LAT_5', 'temp_LONG_5': 'LONG_5',\n",
    "    'temp_LAT_10': 'LAT_10', 'temp_LONG_10': 'LONG_10',\n",
    "    'temp_LAT_15': 'LAT_15', 'temp_LONG_15': 'LONG_15'\n",
    "}\n",
    "df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "\n",
    "# --- Vérification ---\n",
    "print(\"Aperçu du résultat final et propre :\")\n",
    "print(df[['MMSI', 'BaseDateTime', 'LAT', 'LON', 'LAT_5', 'LONG_5', 'LAT_10', 'LONG_10', 'LAT_15', 'LONG_15']].head(10))\n",
    "\n",
    "print(\"\\nInformations sur le remplissage (sans doublons) :\")\n",
    "print(df[['LAT_5', 'LONG_5', 'LAT_10', 'LONG_10', 'LAT_15', 'LONG_15']].info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa85602",
   "metadata": {},
   "source": [
    "Séparation en bases d'apprentissage, test et validation par MMSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d61b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de MMSI uniques:\n",
      "Train: 97\n",
      "Test : 30\n",
      "Val  : 22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Récupération des MMSI uniques et suppr valeurs manquantes\n",
    "mmsi_uniques = df['MMSI'].dropna().unique()\n",
    "\n",
    "# Mélange aléatoire\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(mmsi_uniques)\n",
    "\n",
    "# Affectation fixe : 97 pour apprentissage, 30 pour test, 22 pour validation\n",
    "n_train = 97\n",
    "n_test = 30\n",
    "n_val = 22\n",
    "\n",
    "mmsi_train = mmsi_uniques[:n_train]\n",
    "mmsi_test = mmsi_uniques[n_train:n_train + n_test]\n",
    "mmsi_val = mmsi_uniques[n_train + n_test:n_train + n_test + n_val]\n",
    "\n",
    "# Création des trois sous-ensembles\n",
    "df_train = df[df['MMSI'].isin(mmsi_train)]\n",
    "df_test = df[df['MMSI'].isin(mmsi_test)]\n",
    "df_val = df[df['MMSI'].isin(mmsi_val)]\n",
    "\n",
    "# Affichage pour vérification\n",
    "print(\"Nombre de MMSI uniques:\")\n",
    "print(\"Train:\", df_train['MMSI'].nunique())\n",
    "print(\"Test :\", df_test['MMSI'].nunique())\n",
    "print(\"Val  :\", df_val['MMSI'].nunique())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55fde09",
   "metadata": {},
   "source": [
    "Observation de début de chaque df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771eaa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.head(5))\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"  ===============================================================  \")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(df_test.head(5))\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"  ===============================================================  \")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(df_val.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24268a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sort_values([\"MMSI\",\"BaseDateTime\"], inplace=True)\n",
    "print(df_train.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c849721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Taille de l'ensemble d'apprentissage : {len(df_train)}\")\n",
    "print(f\"Taille de l'ensemble de test : {len(df_test)}\")\n",
    "print(f\"Taille de l'ensemble de validation : {len(df_val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f5eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sort_values([\"MMSI\",\"BaseDateTime\"], inplace=True)\n",
    "print(df_train.head())\n",
    "# print(df_train.iloc[2950:3000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a171d1",
   "metadata": {},
   "source": [
    "prendre entre 295 et 305sec\n",
    "prendre entre 595 et 605sec\n",
    "prendre entre 895 et 905sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44602cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpoler_positions_dataframe(df):\n",
    "    \"\"\"\n",
    "    Fonction pour interpoler les positions à 5, 10 et 15 minutes\n",
    "    pour un dataframe donné\n",
    "    \"\"\"\n",
    "    # Créer une copie pour éviter les warnings\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Trier par MMSI et datetime pour assurer l'ordre chronologique\n",
    "    df_copy = df_copy.sort_values(['MMSI', 'BaseDateTime']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Début de l'interpolation pour {len(df_copy)} lignes...\")\n",
    "    \n",
    "    # Parcourir chaque navire\n",
    "    for mmsi in df_copy['MMSI'].unique():\n",
    "        # Filtrer les données du navire actuel\n",
    "        mask_navire = df_copy['MMSI'] == mmsi\n",
    "        indices_navire = df_copy[mask_navire].index.tolist()\n",
    "        \n",
    "        # Parcourir les positions de ce navire\n",
    "        for i in range(len(indices_navire) - 1):\n",
    "            idx_actuel = indices_navire[i]\n",
    "            idx_suivant = indices_navire[i + 1]\n",
    "            \n",
    "            # Récupérer les positions et temps\n",
    "            lat_A = df_copy.loc[idx_actuel, 'LAT']\n",
    "            lon_A = df_copy.loc[idx_actuel, 'LON']\n",
    "            time_A = df_copy.loc[idx_actuel, 'BaseDateTime']\n",
    "            \n",
    "            lat_B = df_copy.loc[idx_suivant, 'LAT']\n",
    "            lon_B = df_copy.loc[idx_suivant, 'LON']\n",
    "            time_B = df_copy.loc[idx_suivant, 'BaseDateTime']\n",
    "            \n",
    "            # Calculer l'intervalle de temps en secondes\n",
    "            delta_temps = (time_B - time_A).total_seconds()\n",
    "            \n",
    "            # Interpolation à 5 minutes (300s)\n",
    "            if delta_temps >= 300:\n",
    "                fraction_5min = 300 / delta_temps\n",
    "                lat_5min = lat_A + fraction_5min * (lat_B - lat_A)\n",
    "                lon_5min = lon_A + fraction_5min * (lon_B - lon_A)\n",
    "                \n",
    "                df_copy.loc[idx_actuel, 'LAT_5'] = lat_5min\n",
    "                df_copy.loc[idx_actuel, 'LONG_5'] = lon_5min\n",
    "            \n",
    "            # Interpolation à 10 minutes (600s)\n",
    "            if delta_temps >= 600:\n",
    "                fraction_10min = 600 / delta_temps\n",
    "                lat_10min = lat_A + fraction_10min * (lat_B - lat_A)\n",
    "                lon_10min = lon_A + fraction_10min * (lon_B - lon_A)\n",
    "                \n",
    "                df_copy.loc[idx_actuel, 'LAT_10'] = lat_10min\n",
    "                df_copy.loc[idx_actuel, 'LONG_10'] = lon_10min\n",
    "            \n",
    "            # Interpolation à 15 minutes (900s)\n",
    "            if delta_temps >= 900:\n",
    "                fraction_15min = 900 / delta_temps\n",
    "                lat_15min = lat_A + fraction_15min * (lat_B - lat_A)\n",
    "                lon_15min = lon_A + fraction_15min * (lon_B - lon_A)\n",
    "                \n",
    "                df_copy.loc[idx_actuel, 'LAT_15'] = lat_15min\n",
    "                df_copy.loc[idx_actuel, 'LONG_15'] = lon_15min\n",
    "    \n",
    "    print(\"Interpolation terminée !\")\n",
    "    return df_copy\n",
    "\n",
    "# Application de l'interpolation sur les trois ensembles\n",
    "print(\"=== INTERPOLATION DE L'ENSEMBLE D'APPRENTISSAGE ===\")\n",
    "df_train_interpolated = interpoler_positions_dataframe(df_train)\n",
    "\n",
    "print(\"\\n=== INTERPOLATION DE L'ENSEMBLE DE TEST ===\")\n",
    "df_test_interpolated = interpoler_positions_dataframe(df_test)\n",
    "\n",
    "print(\"\\n=== INTERPOLATION DE L'ENSEMBLE DE VALIDATION ===\")\n",
    "df_val_interpolated = interpoler_positions_dataframe(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad118743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier_interpolation(df, nom_ensemble):\n",
    "    \"\"\"\n",
    "    Fonction pour vérifier les résultats de l'interpolation\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== VÉRIFICATION - {nom_ensemble} ===\")\n",
    "    \n",
    "    # Compter les valeurs non nulles pour chaque colonne d'interpolation\n",
    "    interpolations_5min = df['LAT_5'].notna().sum()\n",
    "    interpolations_10min = df['LAT_10'].notna().sum()\n",
    "    interpolations_15min = df['LAT_15'].notna().sum()\n",
    "    \n",
    "    print(f\"Interpolations à 5 minutes : {interpolations_5min}\")\n",
    "    print(f\"Interpolations à 10 minutes : {interpolations_10min}\")\n",
    "    print(f\"Interpolations à 15 minutes : {interpolations_15min}\")\n",
    "    \n",
    "    # Afficher quelques exemples d'interpolation\n",
    "    exemples = df[df['LAT_5'].notna()].head(3)\n",
    "    if len(exemples) > 0:\n",
    "        print(f\"\\nExemples d'interpolation à 5 minutes :\")\n",
    "        for idx, row in exemples.iterrows():\n",
    "            print(f\"MMSI {row['MMSI']} : Position originale ({row['LAT']:.5f}, {row['LON']:.5f}) -> Position à +5min ({row['LAT_5']:.5f}, {row['LONG_5']:.5f})\")\n",
    "\n",
    "# Vérification des trois ensembles\n",
    "verifier_interpolation(df_train_interpolated, \"TRAIN\")\n",
    "verifier_interpolation(df_test_interpolated, \"TEST\")\n",
    "verifier_interpolation(df_val_interpolated, \"VALIDATION\")\n",
    "\n",
    "print(\"\\n=== INTERPOLATION TERMINÉE POUR TOUS LES ENSEMBLES ===\")\n",
    "print(\"Les DataFrames df_train_interpolated, df_test_interpolated et df_val_interpolated\")\n",
    "print(\"contiennent maintenant les positions interpolées dans les colonnes LAT_5, LONG_5, LAT_10, LONG_10, LAT_15, LONG_15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12511e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seuil_SOG = 0.5  # à ajuster selon ton dataset\n",
    "df_filtre = df[df['SOG'] > seuil_SOG].reset_index(drop=True)\n",
    "len(df_filtre)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
